{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFArHAwILAcU"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.metrics import Accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import save_model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am6v1YdeM3ad"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, mask):\n",
        "    augmented_images = []\n",
        "    augmented_masks = []\n",
        "\n",
        "    # Original image\n",
        "    augmented_images.append(image)\n",
        "    augmented_masks.append(mask)\n",
        "\n",
        "    # Horizontal flip\n",
        "    augmented_images.append(np.fliplr(image))\n",
        "    augmented_masks.append(np.fliplr(mask))\n",
        "\n",
        "    # Vertical flip\n",
        "    augmented_images.append(np.flipud(image))\n",
        "    augmented_masks.append(np.flipud(mask))\n",
        "\n",
        "    # Rotate 90 degrees\n",
        "    augmented_images.append(np.rot90(image, k=1))\n",
        "    augmented_masks.append(np.rot90(mask, k=1))\n",
        "\n",
        "    # Rotate 180 degrees\n",
        "    augmented_images.append(np.rot90(image, k=2))\n",
        "    augmented_masks.append(np.rot90(mask, k=2))\n",
        "\n",
        "    # Rotate 270 degrees\n",
        "    augmented_images.append(np.rot90(image, k=3))\n",
        "    augmented_masks.append(np.rot90(mask, k=3))\n",
        "\n",
        "    return augmented_images, augmented_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33Pdr1jfLDJn"
      },
      "outputs": [],
      "source": [
        "# Enhanced U-Net Architecture\n",
        "def enhanced_unet_model(input_shape=(48, 48, 1)):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Contracting Path (Encoder)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(0.1)(p1)  # Adding dropout to prevent overfitting\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(0.1)(p2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(0.2)(p3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(0.2)(p4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "    p5 = Dropout(0.3)(c5)\n",
        "\n",
        "    # Expanding Path (Decoder)\n",
        "    u6 = UpSampling2D((2, 2))(p5)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Concatenate()([c6, c4])  # Skip connection from encoder\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Concatenate()([c7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Concatenate()([c8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Concatenate()([c9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    return Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeb6C86dLKx0",
        "outputId": "d70b79fb-7fe9-48d4-b214-b9f4880cea17"
      },
      "outputs": [],
      "source": [
        "# Load the training and mask datasets\n",
        "X_train = np.load('Xtrain2_b.npy')  # 48x48 images\n",
        "y_train = np.load('Ytrain2_b.npy')  # Segmentation masks\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "y_train = y_train.astype('float32') / 255.0  # Normalize mask values\n",
        "\n",
        "# Reshape to include channels (48x48 -> 48x48x1)\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "y_train = y_train.reshape(-1, 48, 48, 1)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2JjeFWM7HN",
        "outputId": "9c8bf4c6-3304-4a56-bd89-ef60c7493b8e"
      },
      "outputs": [],
      "source": [
        "# Apply augmentation functions\n",
        "augmented_X_train = []\n",
        "augmented_y_train = []\n",
        "\n",
        "for img, mask in zip(X_train, y_train):\n",
        "    imgs, masks = augment_image(img, mask)\n",
        "    augmented_X_train.extend(imgs)\n",
        "    augmented_y_train.extend(masks)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "augmented_X_train = np.array(augmented_X_train)\n",
        "augmented_y_train = np.array(augmented_y_train)\n",
        "\n",
        "# Shuffle the data\n",
        "idx = np.random.permutation(len(augmented_X_train))\n",
        "augmented_X_train = augmented_X_train[idx]\n",
        "augmented_y_train = augmented_y_train[idx]\n",
        "\n",
        "print(\"Augmented X_train shape:\", augmented_X_train.shape)\n",
        "print(\"Augmented y_train shape:\", augmented_y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYOOxFfmNELn",
        "outputId": "b70e71a0-59de-4c11-be73-1824eee320e5"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(augmented_X_train, augmented_y_train, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU4p5PAwp83z"
      },
      "outputs": [],
      "source": [
        "def custom_generator(image_generator, mask_generator):\n",
        "    while True:\n",
        "        X = next(image_generator)  # Change here\n",
        "        y = next(mask_generator)  # Change here\n",
        "        yield X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1YcnWYGpqik"
      },
      "outputs": [],
      "source": [
        "# Step 3: Define the data augmentation\n",
        "data_gen_args = dict(rotation_range=20,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     horizontal_flip=True,\n",
        "                     fill_mode='nearest')\n",
        "\n",
        "# ImageDataGenerator for X (images) and y (masks)\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Provide the same seed for both images and masks so the transformations are applied correspondingly\n",
        "seed = 1\n",
        "image_generator = image_datagen.flow(X_train, batch_size=16, seed=seed)\n",
        "mask_generator = mask_datagen.flow(y_train, batch_size=16, seed=seed)\n",
        "\n",
        "# Combine the image and mask generators\n",
        "train_generator = zip(image_generator, mask_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIwg5E7iMjdd"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VOVXHk0rLVGd",
        "outputId": "4f94cd98-36e6-459a-d4eb-4e308c4eebc9"
      },
      "outputs": [],
      "source": [
        "# Initialize the U-Net model\n",
        "unet = enhanced_unet_model(input_shape=(48, 48, 1))\n",
        "unet.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = unet.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNr9sdEPo3FD",
        "outputId": "47ddd32f-bba1-421d-ff84-9cbd12786833"
      },
      "outputs": [],
      "source": [
        "# Step 4: Initialize the enhanced U-Net model\n",
        "enhanced_unet = enhanced_unet_model(input_shape=(48, 48, 1))\n",
        "enhanced_unet.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model with augmented data\n",
        "history = enhanced_unet.fit(custom_generator(image_generator, mask_generator), steps_per_epoch=len(X_train) // 16, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9MPj8Hf_KZs7",
        "outputId": "52126f3c-ff2a-449e-e5cd-a56d8837a077"
      },
      "outputs": [],
      "source": [
        "# calculate Bacc\n",
        "y_pred = unet.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype(np.uint8)  # Convert probabilities to binary masks\n",
        "\n",
        "y_pred_flat = y_pred.flatten() # flatten\n",
        "y_val_flat = y_val.flatten() # flatten\n",
        "\n",
        "Bacc = balanced_accuracy_score(y_val_flat, y_pred_flat)\n",
        "print(Bacc)\n",
        "\n",
        "# Visualize training history\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to visualize predictions\n",
        "def visualize_predictions(model, X_test, y_val):\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(np.uint8)  # Convert probabilities to binary masks\n",
        "    for i in range(5):  # Visualize 5 random predictions\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(y_val[i].reshape(48, 48), cmap='gray')\n",
        "        plt.title('Original Mask')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(predictions[i].reshape(48, 48), cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.show()\n",
        "\n",
        "# Load test images for visualization (assuming they are in the same shape)\n",
        "X_test = np.load('Xtest2_b.npy').reshape(-1, 48, 48, 1)\n",
        "visualize_predictions(unet, X_val, y_val)\n",
        "\n",
        "pred = unet.predict(X_test)\n",
        "pred = (pred > 0.5).astype(np.uint8)\n",
        "np.save('pred_b.npy', pred)\n",
        "\n",
        "unet.save('unet.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c5qV1M1IOWYE",
        "outputId": "e81adff9-9c6a-4ead-f054-3699ea0cbefa"
      },
      "outputs": [],
      "source": [
        "# calculate Bacc\n",
        "y_pred = enhanced_unet.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype(np.uint8)  # Convert probabilities to binary masks\n",
        "\n",
        "y_pred_flat = y_pred.flatten() # flatten\n",
        "y_val_flat = y_val.flatten() # flatten\n",
        "\n",
        "Bacc = balanced_accuracy_score(y_val_flat, y_pred_flat)\n",
        "print(Bacc)\n",
        "\n",
        "# Visualize training history\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to visualize predictions\n",
        "def visualize_predictions(model, X_test, y_val):\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(np.uint8)  # Convert probabilities to binary masks\n",
        "    for i in range(5):  # Visualize 5 random predictions\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(y_val[i].reshape(48, 48), cmap='gray')\n",
        "        plt.title('Original Mask')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(predictions[i].reshape(48, 48), cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.show()\n",
        "\n",
        "# Load test images for visualization (assuming they are in the same shape)\n",
        "X_test = np.load('Xtest2_b.npy').reshape(-1, 48, 48, 1)\n",
        "visualize_predictions(enhanced_unet, X_val, y_val)\n",
        "\n",
        "pred = enhanced_unet.predict(X_test)\n",
        "pred = (pred > 0.5).astype(np.uint8)\n",
        "print(pred.shape)\n",
        "pred = pred.reshape(-1, 2304)\n",
        "\n",
        "print(pred.shape)\n",
        "print(pred)\n",
        "np.save('pred_b_enhanced.npy', pred)\n",
        "\n",
        "enhanced_unet.save('enhanced_unet.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
